# Monkey: Segmentation-based Lossless Floating-Point Compression

The rapid expansion of IoT devices has led to the generation of vast amounts of time-series data, presenting both opportunities and challenges, particularly in the demand for efficient data storage and transmission solutions. Although mainstream lossless floating-point compression algorithms have achieved high compression ratios, there is a continuous need for further optimization to handle increasingly large datasets. This paper presents Monkey, a novel streaming lossless compression algorithm that enhances the adaptive-length encoding scheme to achieve superior compression performance. Building on the erasing-based method, Monkey employs a segmentation strategy to dynamically locate the consecutive data points in a binary stream during decoding, eliminating the need of traditionally using a stored count. Extensive experiments on 25 datasets demonstrate that Monkey substantially advances many XOR-based state-of-the-art algorithms in lossless compression: It consistently outperforms Elf+ across all tested datasets with 7% average improvement in compression ratio.

## Contributions

- The proposed novel algorithm, Monkey, which dynamically determines data point locations in a variable-length schema during the decoding phase. Monkey processes data streams progressively with linear time complexity and extremely low memory overhead, making it an efficient solution for streaming lossless compression. Unlike existing algorithms such as Gorilla, Chimp/ChimpN, and Elf+, Monkey leverages its unique segmentation strategy, making it a distinct and superior contender in the field.
- The proposed segmentation strategy eliminates the need for length indicators typically required in adaptive-length storage schema. This strategy operates in two phases: first, extracting critical information from the exponent part; and second, completing the remaining decoding based on the data point positions calculated with our computation method. This method transforms binary exponent information into its corresponding decimal equivalent, accurately identifying data point positions involving ``erasing operation''. Although this additional computation introduces minor time costs during decompression, it results in substantial improvements in compression ratio by reduced storage on counts.
- Comprehensive experiments conducted on 25 diverse datasets have revealed that Monkey consistently delivers superior compression performance with the lowest average compression ratio (0.342) and the lowest median compression ratio (0.222) in the comparison with its counterparts. In the comparison, it also achieves the lowest Median Absolute Deviation (MAD) of (0.055) indicating that Monkey is exceptional stabile and robust, reflects small variance around its median. In all tested situations, Monkey surpasses Elf+ and shows a consistent 7.1% average relative improvement in compression ratio.
